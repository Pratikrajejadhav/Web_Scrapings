{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Obtaining dependency information for webdriver_manager from https://files.pythonhosted.org/packages/b1/51/b5c11cf739ac4eecde611794a0ec9df420d0239d51e73bc19eb44f02b48b/webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2023.7.22)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver_manager\n",
      "Successfully installed webdriver_manager-4.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install webdriver_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully navigated to the reviews page.\n",
      "Could not load more reviews: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0108C113+48259]\n",
      "\t(No symbol) [0x0101CA41]\n",
      "\t(No symbol) [0x00F10A17]\n",
      "\t(No symbol) [0x00F50BED]\n",
      "\t(No symbol) [0x00F50C9B]\n",
      "\t(No symbol) [0x00F8BC12]\n",
      "\t(No symbol) [0x00F70DE4]\n",
      "\t(No symbol) [0x00F89B9C]\n",
      "\t(No symbol) [0x00F70B36]\n",
      "\t(No symbol) [0x00F4570D]\n",
      "\t(No symbol) [0x00F462CD]\n",
      "\tGetHandleVerifier [0x013465A3+2908435]\n",
      "\tGetHandleVerifier [0x01383BBB+3159851]\n",
      "\tGetHandleVerifier [0x011250CB+674875]\n",
      "\tGetHandleVerifier [0x0112B28C+699900]\n",
      "\t(No symbol) [0x01026244]\n",
      "\t(No symbol) [0x01022298]\n",
      "\t(No symbol) [0x0102242C]\n",
      "\t(No symbol) [0x01014BB0]\n",
      "\tBaseThreadInitThunk [0x751CFCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77317C5E+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77317C2E+238]\n",
      "\n",
      "Could not extract reviews: Message: \n",
      "\n",
      "Saved 0 reviews to hospital_reviews_2.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "class GoogleReviewsScraper:\n",
    "    def __init__(self, hospital_name):\n",
    "        self.hospital_name = hospital_name\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "\n",
    "\n",
    "    def navigate_to_reviews(self):\n",
    "        search_url = f\"https://www.google.com/search?q={self.hospital_name.replace(' ','+')}+reviews\"\n",
    "        self.driver.get(search_url)\n",
    "        try:\n",
    "            reviews_link = self.wait.until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Google Reviews')))\n",
    "            reviews_link.click()\n",
    "            print(\"Successfully navigated to the reviews page.\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not navigate to the reviews page:\",e)\n",
    "            self.driver.quit()\n",
    "\n",
    "    def load_all_reviews(self):\n",
    "      try:\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "          self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "          time.sleep(2)\n",
    "\n",
    "          self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.BgXiYe')))\n",
    "\n",
    "\n",
    "          new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "          if new_height == last_height:\n",
    "            break\n",
    "          last_height = new_height\n",
    "        # print(\"Loaded more reviews.\")\n",
    "      except Exception as e:\n",
    "        print(\"Could not load more reviews:\", e)\n",
    "        # self.driver.quit()\n",
    "\n",
    "    def extract_reviews(self):\n",
    "      self.reviews = []\n",
    "      try:\n",
    "        review_elements = self.wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.BgXiYe')))\n",
    "        print(f\"Found {len(review_elements)} reviews elements.\")\n",
    "        for element in review_elements:\n",
    "          try:\n",
    "            author_name = element.find_element(By.CSS_SELECTOR, 'div.PuaHbe span.dehysf.lTi8oc').text\n",
    "            review_date = element.find_element(By.CSS_SELECTOR, 'div.PuaHbe span.dehysf.lTi8oc').text\n",
    "            review_snippet = element.find_element(By.CSS_SELECTOR, 'div.review-snippet').text\n",
    "            try:\n",
    "              more_link = element.find_element(By.CSS_SELECTOR, 'a.review-more-link')\n",
    "              more_link.click()\n",
    "              time.sleep(1)\n",
    "              review_text = element.find_element(By.CSS_SELECTOR, 'span.review-full-text').text\n",
    "            except Exception:\n",
    "              review_text = review_snippet\n",
    "            self.reviews.append({\n",
    "              'author': author_name,\n",
    "              'review': review_date,\n",
    "              'review': review_text\n",
    "            })\n",
    "            print(f\"Extracted review by: {author_name}.\")\n",
    "          except Exception as e:\n",
    "            print(\"Could not extract review,Error extracting details for one reviews:\", e)\n",
    "      except Exception as e:\n",
    "        print(\"Could not extract reviews:\", e)\n",
    "        \n",
    "        # self.driver.quit()\n",
    "\n",
    "    def save_reviews_to_json(self, filename='hospital_reviews_2.json'):\n",
    "      with open(filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(self.reviews, file, ensure_ascii=False, indent=4)\n",
    "      # print(f\"Saved reviews to {filename}\")\n",
    "\n",
    "    def close_driver(self):\n",
    "      self.driver.quit()\n",
    "      # print(\"Driver closed.\")\n",
    "\n",
    "    def run_scraper(self):\n",
    "      self.navigate_to_reviews()\n",
    "      self.load_all_reviews()\n",
    "      self.extract_reviews()\n",
    "      # self.save_reviews_to_json()\n",
    "      self.close_driver()\n",
    "      return self.reviews\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # hospital_name = input(\"Enter the name of the hospital: \")\n",
    "    scraper = GoogleReviewsScraper(\"Continental Hospital Hyderabad\")\n",
    "    reviews = scraper.run_scraper()\n",
    "    scraper.save_reviews_to_json()\n",
    "    print(f\"Saved {len(reviews)} reviews to hospital_reviews_2.json\")\n",
    "\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not navigate to the reviews page: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id='ow193']/a\"}\n",
      "  (Session info: chrome=124.0.6367.202); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00D1C113+48259]\n",
      "\t(No symbol) [0x00CACA41]\n",
      "\t(No symbol) [0x00BA0A17]\n",
      "\t(No symbol) [0x00BE0BED]\n",
      "\t(No symbol) [0x00BE0C9B]\n",
      "\t(No symbol) [0x00C1BC12]\n",
      "\t(No symbol) [0x00C00DE4]\n",
      "\t(No symbol) [0x00C19B9C]\n",
      "\t(No symbol) [0x00C00B36]\n",
      "\t(No symbol) [0x00BD570D]\n",
      "\t(No symbol) [0x00BD62CD]\n",
      "\tGetHandleVerifier [0x00FD65A3+2908435]\n",
      "\tGetHandleVerifier [0x01013BBB+3159851]\n",
      "\tGetHandleVerifier [0x00DB50CB+674875]\n",
      "\tGetHandleVerifier [0x00DBB28C+699900]\n",
      "\t(No symbol) [0x00CB6244]\n",
      "\t(No symbol) [0x00CB2298]\n",
      "\t(No symbol) [0x00CB242C]\n",
      "\t(No symbol) [0x00CA4BB0]\n",
      "\tBaseThreadInitThunk [0x751CFCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77317C5E+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77317C2E+238]\n",
      "\n",
      "Could not load more reviews: HTTPConnectionPool(host='localhost', port=59946): Max retries exceeded with url: /session/3a5a048e591a45b4955f9332fa0a7f50/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002E28024D510>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "Could not extract reviews: HTTPConnectionPool(host='localhost', port=59946): Max retries exceeded with url: /session/3a5a048e591a45b4955f9332fa0a7f50/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002E280228DD0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "Saved reviews to hospital_reviews.json\n",
      "Driver closed.\n",
      "Saved 0 reviews to hospital_reviews.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "class GoogleReviewsScraper:\n",
    "    def __init__(self, hospital_name):\n",
    "        self.hospital_name = hospital_name\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "\n",
    "    def navigate_to_reviews(self):\n",
    "        search_url = f\"https://www.google.com/search?q={self.hospital_name.replace(' ', '+')}\"\n",
    "        self.driver.get(search_url)\n",
    "        try:\n",
    "            # reviews_link = self.wait.until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Google Reviews')))\n",
    "            # reviews_link.click()\n",
    "\n",
    "            # reviews_link = self.wait.until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Google Reviews')))\n",
    "            # reviews_link.click()\n",
    "            \n",
    "\n",
    "            button = self.driver.find_element(By.XPATH, \"//*[@id='ow193']/a\")\n",
    "\n",
    "            # Click the button\n",
    "            button.click()\n",
    "\n",
    "            print(\"Successfully navigated to the reviews page.\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not navigate to the reviews page:\", e)\n",
    "            self.driver.quit()\n",
    "\n",
    "    def load_more_reviews(self):\n",
    "        try:\n",
    "            last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.BgXiYe')))\n",
    "                new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            print(\"Loaded more reviews.\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not load more reviews:\", e)\n",
    "            self.driver.quit()\n",
    "\n",
    "    def extract_reviews(self):\n",
    "        self.reviews = []\n",
    "        try:\n",
    "            review_elements = self.wait.until(EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"v-pills-guide\"]/div[2]/section/div[2]')))\n",
    "            print(f\"Found {len(review_elements)} reviews elements.\")\n",
    "            for element in review_elements:\n",
    "                try:\n",
    "                    author_name = element.find_element(By.XPATH, '//*[@id=\"v-pills-guide\"]/div[2]/section/div[2]/div/div/div/div/div/div/div/div/div[1]/div/div/div[2]/div/p[5]').text\n",
    "                    # review_date = element.find_element(By.CSS_SELECTOR, 'div.PuaHbe span.dehysf.lTi8oc').text\n",
    "                    review_text = element.find_element(By.XPATH, '//*[@id=\"v-pills-guide\"]/div[2]/section/div[2]/div/div/div/div/div/div/div/div/div[1]/div/div/div[2]/div').text\n",
    "                    try:\n",
    "                        more_link = element.find_element(By.CSS_SELECTOR, 'a.review-more-link')\n",
    "                        more_link.click()\n",
    "                        time.sleep(1)\n",
    "                        review_text = element.find_element(By.CSS_SELECTOR, 'span.review-full-text').text\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    self.reviews.append({\n",
    "                        'author': author_name,\n",
    "                        # 'date': review_date,\n",
    "                        'review': review_text\n",
    "                    })\n",
    "                    print(f\"Extracted review by: {author_name}.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Could not extract review,Error extracting details for one review:\", e)\n",
    "        except Exception as e:\n",
    "            print(\"Could not extract reviews:\", e)\n",
    "\n",
    "    def save_reviews_to_json(self, filename='hospital_reviews3.json'):\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            json.dump(self.reviews, file, ensure_ascii=False, indent=4)\n",
    "        print(f\"Saved reviews to {filename}\")\n",
    "\n",
    "    def close_driver(self):\n",
    "        self.driver.quit()\n",
    "        print(\"Driver closed.\")\n",
    "\n",
    "    def run_scraper(self):\n",
    "        self.navigate_to_reviews()\n",
    "        self.load_more_reviews()\n",
    "        self.extract_reviews()\n",
    "        self.save_reviews_to_json()\n",
    "        self.close_driver()\n",
    "        return self.reviews\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = GoogleReviewsScraper(\"Continental Hospital Hyderabad\")\n",
    "    reviews = scraper.run_scraper()\n",
    "    print(f\"Saved {len(reviews)} reviews to hospital_reviews.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO Reviews Found on Page\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.google.com/search?q=continental+hospitals#lrd=0x3bcb947fdee4f5a1:0x2ca09b4d2e3a79f,1,,,,\")\n",
    "\n",
    "# Find the element by XPath\n",
    "review_elements = driver.find_elements(By.XPATH, \"//*[@id='reviewSort']/div/div[2]/div[1]\")\n",
    "data = []\n",
    "if review_elements:\n",
    "    for review in review_elements:\n",
    "        print(review)\n",
    "        review_data_dict = {}\n",
    "        review_data_dict['reviewer_name'] = review.find_element(By.XPATH, \".//div[@class='TSUbDb']\").text\n",
    "        review_data_dict['review'] = review.find_element(By.XPATH, \".//span[@class='review-snippet']\").text\n",
    "        data.append(review_data_dict)\n",
    "else:\n",
    "    print('NO Reviews Found on Page')\n",
    "\n",
    "\n",
    "\n",
    "# Extract text content\n",
    "# text_content = element.text\n",
    "\n",
    "# print(\"Text Content:\", text_content)\n",
    "print(data)\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(review)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'review' is not defined"
     ]
    }
   ],
   "source": [
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully navigated to the reviews page.\n",
      "Could not extract reviews: Message: \n",
      "\n",
      "Saved reviews to hospital_reviews.json\n",
      "Saved 0 reviews to hospital_reviews.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "class GoogleReviewsScraper:\n",
    "    def __init__(self, hospital_name):\n",
    "        self.hospital_name = hospital_name\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "\n",
    "\n",
    "    def navigate_to_reviews(self):\n",
    "        search_url = f\"https://www.google.com/search?q={self.hospital_name.replace(' ','+')}+reviews\"\n",
    "        self.driver.get(search_url)\n",
    "        try:\n",
    "            reviews_link = self.wait.until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Google Reviews')))\n",
    "            reviews_link.click()\n",
    "            button = self.driver.find_element(By.XPATH, \"//*[@id='v-pills-guide-tab']\")\n",
    "\n",
    "            # Click the button\n",
    "            button.click()\n",
    "            print(\"Successfully navigated to the reviews page.\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not navigate to the reviews page:\", e)\n",
    "            self.driver.quit()\n",
    "\n",
    "    # def load_more_reviews(self):\n",
    "    #     try:\n",
    "    #         last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    #         while True:\n",
    "    #             self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #             time.sleep(2)\n",
    "\n",
    "    #             self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.BgXiYe')))\n",
    "\n",
    "    #             new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    #             if new_height == last_height:\n",
    "    #                 break\n",
    "    #             last_height = new_height\n",
    "    #         # print(\"Loaded more reviews.\")\n",
    "    #     except Exception as e:\n",
    "    #         print(\"Could not load more reviews:\", e)\n",
    "    #         self.driver.quit()\n",
    "\n",
    "    def extract_reviews(self):\n",
    "        self.reviews = []\n",
    "        try:\n",
    "            review_elements = self.wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.BgXiYe')))\n",
    "            print(f\"Found {len(review_elements)} reviews elements.\")\n",
    "            for element in review_elements:\n",
    "                try:\n",
    "                    author_name = element.find_element(By.CSS_SELECTOR, 'div.PuaHbe span.dehysf.lTi8oc').text\n",
    "                    review_date = element.find_element(By.CSS_SELECTOR, 'div.PuaHbe span.dehysf.lTi8oc').text\n",
    "                    review_text = element.find_element(By.CSS_SELECTOR, 'div.review-snippet').text\n",
    "                    try:\n",
    "                        more_link = element.find_element(By.CSS_SELECTOR, 'a.review-more-link')\n",
    "                        more_link.click()\n",
    "                        time.sleep(1)\n",
    "                        review_text = element.find_element(By.CSS_SELECTOR, 'span.review-full-text').text\n",
    "                    except Exception:\n",
    "                        review_text = review_snippet\n",
    "                    self.reviews.append({\n",
    "                        'author': author_name,\n",
    "                        'date': review_date,\n",
    "                        'review': review_text\n",
    "                    })\n",
    "                    print(f\"Extracted review by: {author_name}.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Could not extract review,Error extracting details for one review:\", e)\n",
    "        except Exception as e:\n",
    "            print(\"Could not extract reviews:\", e)\n",
    "\n",
    "    def save_reviews_to_json(self, filename='hospital_reviews.json'):\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            json.dump(self.reviews, file, ensure_ascii=False, indent=4)\n",
    "        print(f\"Saved reviews to {filename}\")\n",
    "\n",
    "    def close_driver(self):\n",
    "        self.driver.quit()\n",
    "        # print(\"Driver closed.\")\n",
    "\n",
    "    def run_scraper(self):\n",
    "        self.navigate_to_reviews()\n",
    "        # self.load_more_reviews()\n",
    "        self.extract_reviews()\n",
    "        # self.save_reviews_to_json()\n",
    "        self.close_driver()\n",
    "        return self.reviews\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hospital_name = input(\"Enter the name of the hospital: \")\n",
    "    scraper = GoogleReviewsScraper(hospital_name)\n",
    "    reviews = scraper.run_scraper()\n",
    "    scraper.save_reviews_to_json()\n",
    "    print(f\"Saved {len(reviews)} reviews to hospital_reviews.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
