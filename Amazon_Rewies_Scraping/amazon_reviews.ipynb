{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentiment_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment_analysis.py\n",
    "# Importing necessary modules\n",
    "import streamlit as st \n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "import pandas as pd\n",
    "# scraping start \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "\n",
    "# Web driver\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "\n",
    "def scrape_reviews(url, max_page=2):\n",
    "    driver = webdriver.Chrome()\n",
    "    reviews = []\n",
    "\n",
    "    for page in range(1, max_page + 1):\n",
    "        print(\"Page:\", page)\n",
    "        page_url = f'{url}{page}?ie=UTF8&reviewerType=all_reviews&pageNumber={page}'\n",
    "        driver.get(page_url)\n",
    "\n",
    "        review_elements = driver.find_elements(By.XPATH, \"//div[@data-hook='review']\")\n",
    "        if review_elements:\n",
    "            for review in review_elements:\n",
    "                review_data_dict = {}\n",
    "                review_data_dict['reviewer_name'] = review.find_element(By.XPATH, \".//span[@class='a-profile-name']\").text\n",
    "                review_data_dict['review_date'] = review.find_element(By.XPATH, \".//span[@data-hook='review-date']\").text\n",
    "              \n",
    "                review_data_dict['rating'] = review.find_element(By.XPATH, \".//i[contains(@class, 'review-rating')]/span\").get_attribute('innerText')\n",
    "                \n",
    "                # review_data_dict['rating'] = \"Rating not found\"\n",
    "                review_data_dict['review_text'] = review.find_element(By.XPATH, \".//span[@data-hook='review-body']\").text\n",
    "                reviews.append(review_data_dict)\n",
    "        else:\n",
    "            print(f'NO Reviews Found on Page {page}')\n",
    "            break\n",
    "\n",
    "        # Clicking on the next page button\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//li[@class='a-last']//a\")\n",
    "            next_button.click()\n",
    "            WebDriverWait(driver, 10).until(EC.url_changes(page_url))\n",
    "        except NoSuchElementException:\n",
    "            print(\"Next Page not found\")\n",
    "            break\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# web_page_url = \"https://www.amazon.in/Apple-iPhone-13-128GB-Blue/product-reviews/B09G9BL5CP/ref=cm_cr_arp_d_paging_btm_next_\"\n",
    "\n",
    "\n",
    "\n",
    "# scraping ends here\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCKESnAOIkl8fIqV-KHOUx5pF-ythxJ1Ng\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    st.header(\"Sentiment Analysis of Reviews\")\n",
    "    # data = st.sidebar.file_uploader(\"Upload Data File Here\", type=['csv'])\n",
    "\n",
    "    full_link = st.sidebar.text_input(\"Enter the link Here\")\n",
    "    btn =  st.sidebar.button(\"start\")\n",
    "\n",
    "\n",
    "    if btn:\n",
    "\n",
    "        # full_link = \"https://www.amazon.in/Apple-iPhone-13-128GB-Blue/product-reviews/B09G9BL5CP/ref=cm_cr_arp_d_paging_btm_next_1?ie=UTF8&reviewerType=all_reviews&pageNumber=1\"\n",
    "\n",
    "        # Define a regular expression pattern to extract the desired part of the link\n",
    "        pattern = r'(https://www.amazon.in/[^/]+/product-reviews/[^/]+/ref=cm_cr_arp_d_paging_btm_next_)'\n",
    "\n",
    "        # Use re.search to find the pattern in the link\n",
    "        match = re.search(pattern, full_link)\n",
    "\n",
    "        if match:\n",
    "            extracted_part = match.group(1)\n",
    "            print(extracted_part)\n",
    "            amazon_reviews = scrape_reviews(extracted_part)\n",
    "        else:\n",
    "            print(\"Pattern not found in the link.\")\n",
    "\n",
    "        # amazon_reviews = scrape_reviews(web_page_url)\n",
    "\n",
    "        # print(amazon_reviews)\n",
    "\n",
    "\n",
    "\n",
    "        data_file = pd.DataFrame(amazon_reviews)\n",
    "        data_file['date'] = data_file['review_date'].str.extract(r'on (\\d+ \\w+ \\d{4})')\n",
    "        data_file['date'] = pd.to_datetime(data_file['date'], format='%d %B %Y')\n",
    "        if data_file is not None:\n",
    "            # data_file  = pd.read_csv(data)\n",
    "            # data_file = pd.DataFrame(amazon_reviews)\n",
    "            Sentiment = []\n",
    "            for reviews in data_file['review_text']:\n",
    "             \n",
    "                # model selection\n",
    "                model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "                prompt = \"\"\" Give the Sentiment analysis of given review only in three words either **POSITIVE**üëçüèª or **NEGATIVE** üëéüèª \n",
    "                consider one more condition if the review is to larger consider it **spam** \"\"\"\n",
    "\n",
    "                response = model.generate_content([prompt, reviews])\n",
    "                #  st.write(reviews)\n",
    "                #  st.write(response.text)\n",
    "                Sentiment.append(response.text)\n",
    "                #  st.write(\"===============================================================================\")\n",
    "\n",
    "            data_file['Sentiment'] = Sentiment\n",
    "            data_file.drop(columns=['review_date'], inplace=True)\n",
    "            data_file = data_file.sort_values(by='date', ascending=False).reset_index(drop=True)\n",
    "            st.write(data_file)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sagar Behera</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>5</td>\n",
       "      <td>Go fr it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gundabattina SaradhiMuneendra</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous üòçLoved itCamera awesome üòòPerformance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anshul Duhan</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>5</td>\n",
       "      <td>Best in class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anirudhya  Ghosh</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>5</td>\n",
       "      <td>Premium Colour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ashutosh  Singh</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>5</td>\n",
       "      <td>Blue colour is very lightBut performance is ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>5</td>\n",
       "      <td>Just See the beauty of Camera omg üòò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jackson .</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>5</td>\n",
       "      <td>Video superCemara super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Avinan Vaidya</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>This is second iPhone love it üòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>madhusudhana  R</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>4</td>\n",
       "      <td>Good product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bibhu Bisoi</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>5</td>\n",
       "      <td>Best experience luv it‚ù§Ô∏èüî•üî•</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Customer Name           Review Title Rating  \\\n",
       "0                   Sagar Behera    Best in the market!      5   \n",
       "1  Gundabattina SaradhiMuneendra  Mind-blowing purchase      5   \n",
       "2                   Anshul Duhan              Must buy!      5   \n",
       "3               Anirudhya  Ghosh      Worth every penny      5   \n",
       "4                Ashutosh  Singh              Must buy!      5   \n",
       "5              Flipkart Customer       Perfect product!      5   \n",
       "6                      Jackson .              Must buy!      5   \n",
       "7                  Avinan Vaidya         Simply awesome      5   \n",
       "8                madhusudhana  R            Pretty good      4   \n",
       "9                    Bibhu Bisoi               Terrific      5   \n",
       "\n",
       "                                             Comment  \n",
       "0                                           Go fr it  \n",
       "1  Fabulous üòçLoved itCamera awesome üòòPerformance ...  \n",
       "2                                      Best in class  \n",
       "3                                     Premium Colour  \n",
       "4  Blue colour is very lightBut performance is ve...  \n",
       "5                Just See the beauty of Camera omg üòò  \n",
       "6                            Video superCemara super  \n",
       "7                   This is second iPhone love it üòçüòç  \n",
       "8                                       Good product  \n",
       "9                         Best experience luv it‚ù§Ô∏èüî•üî•  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# User-Agent and Accept-Language headers\n",
    "headers = {\n",
    "    'User-Agent': 'Use your own user agent',\n",
    "    'Accept-Language': 'en-us,en;q=0.5'\n",
    "}\n",
    "customer_names = []\n",
    "review_title = []\n",
    "ratings = []\n",
    "comments = []\n",
    "\n",
    "for i in range(1,2):\n",
    "    # Construct the URL for the current page\n",
    "    \n",
    "    url = \"https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART&page=\"+str(i)\n",
    "   \n",
    "    # Send a GET request to the page\n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Extract customer names\n",
    "    names = soup.find_all('p', class_='_2NsDsF AwS1CA')\n",
    "    for name in names:\n",
    "        customer_names.append(name.get_text())\n",
    "\n",
    "    # Extract review titles\n",
    "    title = soup.find_all('p', class_='z9E0IG')\n",
    "    for t in title:\n",
    "        review_title.append(t.get_text())\n",
    "\n",
    "    # Extract ratings\n",
    "    rat = soup.find_all('div', class_=['XQDdHH Ga3i8K', 'XQDdHH Czs3gR Ga3i8K' , 'XQDdHH Js30Fc Ga3i8K'])\n",
    "    for r in rat:\n",
    "        rating = r.get_text()\n",
    "        if rating:\n",
    "            ratings.append(rating)\n",
    "        else:\n",
    "            ratings.append('0')  # Replace null ratings with 0\n",
    "\n",
    "    # Extract comments\n",
    "    cmt = soup.find_all('div', class_='ZmyHeo')\n",
    "    for c in cmt:\n",
    "        comment_text = c.div.div.get_text(strip=True)\n",
    "        comments.append(comment_text)\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "min_length = min(len(customer_names), len(review_title), len(ratings), len(comments))\n",
    "customer_names = customer_names[:min_length]\n",
    "review_title = review_title[:min_length]\n",
    "ratings = ratings[:min_length]\n",
    "comments = comments[:min_length]\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'Customer Name': customer_names,\n",
    "    'Review Title': review_title,\n",
    "    'Rating': ratings,\n",
    "    'Comment': comments\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting assignment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile assignment.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "# User-Agent and Accept-Language headers\n",
    "headers = {\n",
    "    'User-Agent': 'Use your own user agent',\n",
    "    'Accept-Language': 'en-us,en;q=0.5'\n",
    "}\n",
    "\n",
    "customer_names = []\n",
    "review_title = []\n",
    "ratings = []\n",
    "comments = []\n",
    "\n",
    "for i in range(1, 2):\n",
    "    # Construct the URL for the current page\n",
    "    url = \"https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART&page=\" + str(i)\n",
    "   \n",
    "    # Send a GET request to the page\n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Extract customer names\n",
    "    names = soup.find_all('p', class_='_2NsDsF AwS1CA')\n",
    "    for name in names:\n",
    "        customer_names.append(name.get_text())\n",
    "\n",
    "    # Extract review titles\n",
    "    title = soup.find_all('p', class_='z9E0IG')\n",
    "    for t in title:\n",
    "        review_title.append(t.get_text())\n",
    "\n",
    "    # Extract ratings\n",
    "    rat = soup.find_all('div', class_=['XQDdHH Ga3i8K', 'XQDdHH Czs3gR Ga3i8K' , 'XQDdHH Js30Fc Ga3i8K'])\n",
    "    for r in rat:\n",
    "        rating = r.get_text()\n",
    "        if rating:\n",
    "            ratings.append(rating)\n",
    "        else:\n",
    "            ratings.append('0')  # Replace null ratings with 0\n",
    "\n",
    "    # Extract comments\n",
    "    cmt = soup.find_all('div', class_='t-ZTKy')\n",
    "    for c in cmt:\n",
    "        comment_text = c.div.div.get_text(strip=True)\n",
    "        comments.append(comment_text)\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "min_length = min(len(customer_names), len(review_title), len(ratings), len(comments))\n",
    "customer_names = customer_names[:min_length]\n",
    "review_title = review_title[:min_length]\n",
    "ratings = ratings[:min_length]\n",
    "comments = comments[:min_length]\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'Customer Name': customer_names,\n",
    "    'Review Title': review_title,\n",
    "    'Rating': ratings,\n",
    "    'Comment': comments\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Flipkart Product Reviews')\n",
    "st.write('This app displays reviews for a product scraped from Flipkart.')\n",
    "\n",
    "if st.button('Show Reviews'):\n",
    "    st.write(df)\n",
    "\n",
    "# Run Streamlit app: `streamlit run app.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
