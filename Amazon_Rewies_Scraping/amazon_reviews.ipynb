{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentiment_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment_analysis.py\n",
    "# Importing necessary modules\n",
    "import streamlit as st \n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "import pandas as pd\n",
    "# scraping start \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "\n",
    "# Web driver\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "\n",
    "def scrape_reviews(url, max_page=5):\n",
    "    driver = webdriver.Chrome()\n",
    "    reviews = []\n",
    "\n",
    "    for page in range(1, max_page + 1):\n",
    "        print(\"Page:\", page)\n",
    "        page_url = f'{url}{page}?ie=UTF8&reviewerType=all_reviews&pageNumber={page}'\n",
    "        driver.get(page_url)\n",
    "\n",
    "        review_elements = driver.find_elements(By.XPATH, \"//div[@data-hook='review']\")\n",
    "        if review_elements:\n",
    "            for review in review_elements:\n",
    "                review_data_dict = {}\n",
    "                review_data_dict['reviewer_name'] = review.find_element(By.XPATH, \".//span[@class='a-profile-name']\").text\n",
    "                review_data_dict['review_date'] = review.find_element(By.XPATH, \".//span[@data-hook='review-date']\").text\n",
    "              \n",
    "                review_data_dict['rating'] = review.find_element(By.XPATH, \".//i[contains(@class, 'review-rating')]/span\").get_attribute('innerText')\n",
    "                \n",
    "                # review_data_dict['rating'] = \"Rating not found\"\n",
    "                review_data_dict['review_text'] = review.find_element(By.XPATH, \".//span[@data-hook='review-body']\").text\n",
    "                reviews.append(review_data_dict)\n",
    "        else:\n",
    "            print(f'NO Reviews Found on Page {page}')\n",
    "            break\n",
    "\n",
    "        # Clicking on the next page button\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//li[@class='a-last']//a\")\n",
    "            next_button.click()\n",
    "            WebDriverWait(driver, 10).until(EC.url_changes(page_url))\n",
    "        except NoSuchElementException:\n",
    "            print(\"Next Page not found\")\n",
    "            break\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# web_page_url = \"https://www.amazon.in/Apple-iPhone-13-128GB-Blue/product-reviews/B09G9BL5CP/ref=cm_cr_arp_d_paging_btm_next_\"\n",
    "\n",
    "\n",
    "\n",
    "# scraping ends here\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"<your api key>\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    st.header(\"Sentiment Analysis of Reviews\")\n",
    "    # data = st.sidebar.file_uploader(\"Upload Data File Here\", type=['csv'])\n",
    "\n",
    "    full_link = st.sidebar.text_input(\"Enter the link Here\")\n",
    "    btn =  st.sidebar.button(\"start\")\n",
    "\n",
    "\n",
    "    if btn:\n",
    "\n",
    "        # full_link = \"https://www.amazon.in/Apple-iPhone-13-128GB-Blue/product-reviews/B09G9BL5CP/ref=cm_cr_arp_d_paging_btm_next_1?ie=UTF8&reviewerType=all_reviews&pageNumber=1\"\n",
    "\n",
    "        # Define a regular expression pattern to extract the desired part of the link\n",
    "        pattern = r'(https://www.amazon.in/[^/]+/product-reviews/[^/]+/ref=cm_cr_arp_d_paging_btm_next_)'\n",
    "\n",
    "        # Use re.search to find the pattern in the link\n",
    "        match = re.search(pattern, full_link)\n",
    "\n",
    "        if match:\n",
    "            extracted_part = match.group(1)\n",
    "            print(extracted_part)\n",
    "            amazon_reviews = scrape_reviews(extracted_part)\n",
    "        else:\n",
    "            print(\"Pattern not found in the link.\")\n",
    "\n",
    "        # amazon_reviews = scrape_reviews(web_page_url)\n",
    "\n",
    "        # print(amazon_reviews)\n",
    "\n",
    "\n",
    "\n",
    "        data_file = pd.DataFrame(amazon_reviews)\n",
    "        data_file['date'] = data_file['review_date'].str.extract(r'on (\\d+ \\w+ \\d{4})')\n",
    "        data_file['date'] = pd.to_datetime(data_file['date'], format='%d %B %Y')\n",
    "        if data_file is not None:\n",
    "            # data_file  = pd.read_csv(data)\n",
    "            # data_file = pd.DataFrame(amazon_reviews)\n",
    "            Sentiment = []\n",
    "            for reviews in data_file['review_text']:\n",
    "             \n",
    "                # model selection\n",
    "                model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "                prompt = \"\"\" Give the Sentiment analysis of given review only in three words either **POSITIVE**üëçüèª or **NEGATIVE** üëéüèª \n",
    "                consider one more condition if the review is to larger consider it **spam** \"\"\"\n",
    "\n",
    "                response = model.generate_content([prompt, reviews])\n",
    "                #  st.write(reviews)\n",
    "                #  st.write(response.text)\n",
    "                Sentiment.append(response.text)\n",
    "                #  st.write(\"===============================================================================\")\n",
    "\n",
    "            data_file['Sentiment'] = Sentiment\n",
    "            data_file.drop(columns=['review_date'], inplace=True)\n",
    "            data_file = data_file.sort_values(by='date', ascending=False).reset_index(drop=True)\n",
    "            st.write(data_file)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sagar Behera</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>5</td>\n",
       "      <td>Go fr it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anshul Duhan</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>5</td>\n",
       "      <td>Best in class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gundabattina SaradhiMuneendra</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous üòçLoved itCamera awesome üòòPerformance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashutosh  Singh</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>5</td>\n",
       "      <td>Blue colour is very lightBut performance is ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anirudhya  Ghosh</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>5</td>\n",
       "      <td>Premium Colour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Sriram Rajendran</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Abhishek Kundu</td>\n",
       "      <td>Really Nice</td>\n",
       "      <td>4</td>\n",
       "      <td>1st assemble in IND iPhone.Most value for mone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Boopathi Raja</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>3</td>\n",
       "      <td>Im facing heating issues while charging time m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Harshit Singh</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>5</td>\n",
       "      <td>Iphone 15 plus is amazing lineup by apple brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Vinay Manjhi</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent product.Black Queen. üñ§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Customer Name           Review Title Rating  \\\n",
       "0                    Sagar Behera    Best in the market!      5   \n",
       "1                    Anshul Duhan              Must buy!      5   \n",
       "2   Gundabattina SaradhiMuneendra  Mind-blowing purchase      5   \n",
       "3                 Ashutosh  Singh              Must buy!      5   \n",
       "4                Anirudhya  Ghosh      Worth every penny      5   \n",
       "..                            ...                    ...    ...   \n",
       "95               Sriram Rajendran              Fabulous!      5   \n",
       "96                 Abhishek Kundu            Really Nice      4   \n",
       "97                  Boopathi Raja         Decent product      3   \n",
       "98                  Harshit Singh       Perfect product!      5   \n",
       "99                   Vinay Manjhi      Worth every penny      5   \n",
       "\n",
       "                                              Comment  \n",
       "0                                            Go fr it  \n",
       "1                                       Best in class  \n",
       "2   Fabulous üòçLoved itCamera awesome üòòPerformance ...  \n",
       "3   Blue colour is very lightBut performance is ve...  \n",
       "4                                      Premium Colour  \n",
       "..                                                ...  \n",
       "95                                               Nice  \n",
       "96  1st assemble in IND iPhone.Most value for mone...  \n",
       "97  Im facing heating issues while charging time m...  \n",
       "98    Iphone 15 plus is amazing lineup by apple brand  \n",
       "99                   Excellent product.Black Queen. üñ§  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# User-Agent and Accept-Language headers\n",
    "headers = {\n",
    "    'User-Agent': 'Use your own user agent',\n",
    "    'Accept-Language': 'en-us,en;q=0.5'\n",
    "}\n",
    "customer_names = []\n",
    "review_title = []\n",
    "ratings = []\n",
    "comments = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    # Construct the URL for the current page\n",
    "    \n",
    "    url = \"https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART&page=\"+str(i)\n",
    "   \n",
    "    # Send a GET request to the page\n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Extract customer names\n",
    "    names = soup.find_all('p', class_='_2NsDsF AwS1CA')\n",
    "    for name in names:\n",
    "        customer_names.append(name.get_text())\n",
    "\n",
    "    # Extract review titles\n",
    "    title = soup.find_all('p', class_='z9E0IG')\n",
    "    for t in title:\n",
    "        review_title.append(t.get_text())\n",
    "\n",
    "    # Extract ratings\n",
    "    rat = soup.find_all('div', class_=['XQDdHH Ga3i8K', 'XQDdHH Czs3gR Ga3i8K' , 'XQDdHH Js30Fc Ga3i8K'])\n",
    "    for r in rat:\n",
    "        rating = r.get_text()\n",
    "        if rating:\n",
    "            ratings.append(rating)\n",
    "        else:\n",
    "            ratings.append('0')  # Replace null ratings with 0\n",
    "\n",
    "    # Extract comments\n",
    "    cmt = soup.find_all('div', class_='ZmyHeo')\n",
    "    for c in cmt:\n",
    "        comment_text = c.div.div.get_text(strip=True)\n",
    "        comments.append(comment_text)\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "min_length = min(len(customer_names), len(review_title), len(ratings), len(comments))\n",
    "customer_names = customer_names[:min_length]\n",
    "review_title = review_title[:min_length]\n",
    "ratings = ratings[:min_length]\n",
    "comments = comments[:min_length]\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'Customer Name': customer_names,\n",
    "    'Review Title': review_title,\n",
    "    'Rating': ratings,\n",
    "    'Comment': comments\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vdghcczhjzychjhgc\n",
    "\n",
    "\n",
    "# https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# User-Agent and Accept-Language headers\n",
    "headers = {\n",
    "    'User-Agent': 'Use your own user agent',\n",
    "    'Accept-Language': 'en-us,en;q=0.5'\n",
    "}\n",
    "customer_names = []\n",
    "review_title = []\n",
    "ratings = []\n",
    "comments = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    # Construct the URL for the current page\n",
    "    \n",
    "    url = \"https://www.flipkart.com/apple-iphone-15-plus-black-256-gb/product-reviews/itm4b0608e773fc5?pid=MOBGTAGPWKT2VSBB&lid=LSTMOBGTAGPWKT2VSBBYV0FGC&marketplace=FLIPKART&page=\"+str(i)\n",
    "   \n",
    "    # Send a GET request to the page\n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Extract customer names\n",
    "    names = soup.find_all('p', class_='_2NsDsF AwS1CA')\n",
    "    for name in names:\n",
    "        customer_names.append(name.get_text())\n",
    "\n",
    "    # Extract review titles\n",
    "    title = soup.find_all('p', class_='z9E0IG')\n",
    "    for t in title:\n",
    "        review_title.append(t.get_text())\n",
    "\n",
    "    # Extract ratings\n",
    "    rat = soup.find_all('div', class_=['XQDdHH Ga3i8K', 'XQDdHH Czs3gR Ga3i8K' , 'XQDdHH Js30Fc Ga3i8K'])\n",
    "    for r in rat:\n",
    "        rating = r.get_text()\n",
    "        if rating:\n",
    "            ratings.append(rating)\n",
    "        else:\n",
    "            ratings.append('0')  # Replace null ratings with 0\n",
    "\n",
    "    # Extract comments\n",
    "    cmt = soup.find_all('div', class_='ZmyHeo')\n",
    "    for c in cmt:\n",
    "        comment_text = c.div.div.get_text(strip=True)\n",
    "        comments.append(comment_text)\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "min_length = min(len(customer_names), len(review_title), len(ratings), len(comments))\n",
    "customer_names = customer_names[:min_length]\n",
    "review_title = review_title[:min_length]\n",
    "ratings = ratings[:min_length]\n",
    "comments = comments[:min_length]\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'Customer Name': customer_names,\n",
    "    'Review Title': review_title,\n",
    "    'Rating': ratings,\n",
    "    'Comment': comments\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
